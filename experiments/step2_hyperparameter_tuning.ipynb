{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programming\\IDE\\Anaconda\\envs\\hons\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from nvita.utils import open_json\n",
    "from nvita.models.data import SplittedTSData\n",
    "from nvita.models.cnn import CNN\n",
    "from nvita.models.lstm import LSTM\n",
    "from nvita.models.gru import GRU\n",
    "from nvita.models.rf import RF\n",
    "import nvita.models.train as mt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seeds': ['2210', '9999', '58361', '789789', '1111111'], 'data': ['Electricity', 'NZTemp', 'CNYExch', 'Oil'], 'y_col_name': ['Consumption', 'Auckland', 'Close', 'Close'], 'window_size': ['4', '3', '7', '7'], 'models': ['CNN', 'LSTM', 'GRU', 'RF'], 'attacks': ['FGSM', 'BIM', 'nVITA', 'fullVITA']}\n"
     ]
    }
   ],
   "source": [
    "PATH_ROOT = Path(os.getcwd()).parent.absolute()\n",
    "\n",
    "my_metadata = open_json(os.path.join(\n",
    "    PATH_ROOT, \"experiments\", \"metadata.json\"))\n",
    "print(my_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = my_metadata[\"seeds\"]\n",
    "DATA_NAMES =  my_metadata[\"data\"]\n",
    "Y_COL_NAMES = my_metadata[\"y_col_name\"]\n",
    "WINDOW_SIZES = my_metadata[\"window_size\"]\n",
    "MODELS = my_metadata[\"models\"]\n",
    "TEST_SIZE = 100\n",
    "VALID_PER = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split All Dataset for All Seeds and Save them on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Electricity_seed_2210.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Electricity_seed_9999.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Electricity_seed_58361.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Electricity_seed_789789.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Electricity_seed_1111111.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_NZTemp_seed_2210.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_NZTemp_seed_9999.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_NZTemp_seed_58361.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_NZTemp_seed_789789.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_NZTemp_seed_1111111.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_CNYExch_seed_2210.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_CNYExch_seed_9999.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_CNYExch_seed_58361.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_CNYExch_seed_789789.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_CNYExch_seed_1111111.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Oil_seed_2210.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Oil_seed_9999.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Oil_seed_58361.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Oil_seed_789789.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Oil_seed_1111111.pkl has already existed!\n"
     ]
    }
   ],
   "source": [
    "for data_ind in range(len(DATA_NAMES)):\n",
    "    for seed in SEEDS:\n",
    "        path_df = os.path.join(PATH_ROOT, \"data\", \"clean_data\", DATA_NAMES[data_ind] +\".csv\")\n",
    "\n",
    "        s_data = SplittedTSData(path_df, DATA_NAMES[data_ind], Y_COL_NAMES[data_ind], int(WINDOW_SIZES[data_ind]), int(seed))\n",
    "        s_data.train_valid_test_split(TEST_SIZE, VALID_PER)\n",
    "        s_data.save_splitted_data(PATH_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_cnn(s_d):\n",
    "    max_epochs = [100, 250, 500]\n",
    "    learning_rate = [0.001, 0.005, 0.01]\n",
    "    window_size = s_data.window_size\n",
    "    #module__window_size = window_size\n",
    "    module__conv_out_and_f1 = [64, 128, 256]\n",
    "    f0 = s_d.X_train.shape[2]\n",
    "    #module__f1 = [64, 128, 256, 512]\n",
    "    module__f2 = [32, 64 ,128]\n",
    "    out = s_d.y_train.shape[1]\n",
    "\n",
    "    best_score = np.Inf\n",
    "    best_cnn_paras = []\n",
    "    for epoch in max_epochs:\n",
    "        for lr in learning_rate: \n",
    "            for c in module__conv_out_and_f1:\n",
    "                f1 = c\n",
    "                for f2 in module__f2:\n",
    "                    model = CNN(window_size, c, f0, f1, f2, out)\n",
    "                    mt.train(model, lr, epoch, s_d.X_train, s_d.y_train)\n",
    "                    score = np.mean(mt.evaluate(model, s_d.X_valid, s_d.y_valid)**2)\n",
    "                    if score < best_score:\n",
    "                        # Smaller score MSE indicates better performance\n",
    "                        best_score = score\n",
    "                        best_cnn_paras = [epoch, lr, window_size, c, f0, f1, f2, out]\n",
    "    print(\"Best Score for \" + model_name + \" is \" + str(best_score) + \" on dataset \" + str(s_d.df_name))\n",
    "    return best_cnn_paras\n",
    "\n",
    "def grid_search_rnn(s_d, model_name = \"LSTM\"):\n",
    "    max_epochs = [100, 250, 500]\n",
    "    learning_rate = [0.001, 0.005, 0.01]\n",
    "    #module__window_size = window_size\n",
    "    input_dim = s_d.X_train.shape[2]\n",
    "    module__hidden_dim = [64, 128, 256]\n",
    "    module__num_layers = [1, 2, 4]\n",
    "    output_dim = s_d.y_train.shape[1]\n",
    "\n",
    "    best_score = np.Inf\n",
    "    best_rnn_paras = []\n",
    "    for epoch in max_epochs:\n",
    "        for lr in learning_rate: \n",
    "            for hidden_dim in module__hidden_dim:\n",
    "                for num_layers in module__num_layers:\n",
    "                    if model_name == \"LSTM\":\n",
    "                        model = LSTM(input_dim, hidden_dim, num_layers, output_dim)\n",
    "                    elif model_name == \"GRU\":\n",
    "                        model = GRU(input_dim, hidden_dim, num_layers, output_dim)\n",
    "                    mt.train(model, lr, epoch, s_d.X_train, s_d.y_train)\n",
    "                    score = np.mean(mt.evaluate(model, s_d.X_valid, s_d.y_valid)**2)\n",
    "                    if score < best_score:\n",
    "                        # Smaller score MSE indicates better performance\n",
    "                        best_score = score\n",
    "                        best_rnn_paras = [epoch, lr, input_dim, hidden_dim, num_layers, output_dim]\n",
    "    print(\"Best Score for \" + model_name + \" is \" + str(best_score) + \" on dataset \" + str(s_d.df_name))\n",
    "    return best_rnn_paras\n",
    "\n",
    "def grid_search_rf(s_d):\n",
    "    module__n_estimators = [100, 250, 500, 1000]\n",
    "\n",
    "    best_score = np.Inf\n",
    "    best_rf_paras = []\n",
    "    for n_estimators in module__n_estimators:\n",
    "        model = RF(n_estimators)\n",
    "        model.fit(s_d.X_train, s_d.y_train)\n",
    "        score = np.mean(mt.evaluate(model, s_d.X_valid, s_d.y_valid)**2)\n",
    "        if score < best_score:\n",
    "            # Smaller score MSE indicates better performance\n",
    "            best_score = score\n",
    "            best_rf_paras = [n_estimators]\n",
    "    print(\"Best Score for \" + model_name + \" is \" + str(best_score) + \" on dataset \" + str(s_d.df_name))\n",
    "    return best_rf_paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for CNN is 0.008788654 on dataset Electricity\n",
      "Best Score for LSTM is 0.0103443805 on dataset Electricity\n",
      "Best Score for GRU is 0.010461737 on dataset Electricity\n",
      "Best Score for RF is 0.008242441980566248 on dataset Electricity\n",
      "Best Score for CNN is 0.00413001 on dataset NZTemp\n"
     ]
    }
   ],
   "source": [
    "best_cnn_paras_dict = dict()\n",
    "bset_lstm_paras_dict = dict()\n",
    "best_gru_paras_dict = dict()\n",
    "best_rf_paras_dict = dict()\n",
    "for data_ind in range(len(DATA_NAMES)):\n",
    "    seed = SEEDS[0]\n",
    "    s_data = SplittedTSData()\n",
    "    s_data = s_data.load_splitted_data(PATH_ROOT, DATA_NAMES[data_ind], seed)\n",
    "    for model_name in MODELS:\n",
    "        if model_name == \"CNN\":\n",
    "            best_cnn_paras_dict[DATA_NAMES[data_ind]] = grid_search_cnn(s_data)\n",
    "        elif model_name == \"LSTM\":\n",
    "            bset_lstm_paras_dict[DATA_NAMES[data_ind]] = grid_search_rnn(s_data, model_name)\n",
    "        elif model_name == \"GRU\":\n",
    "            best_gru_paras_dict[DATA_NAMES[data_ind]] = grid_search_rnn(s_data, model_name)\n",
    "        elif model_name == \"RF\":\n",
    "            best_rf_paras_dict[DATA_NAMES[data_ind]] = grid_search_rf(s_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('hons')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c602aa022b826db5d2ce365c7625b4d6ed5ee23662e175f9578855d0b85dec78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
