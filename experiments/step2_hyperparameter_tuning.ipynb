{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from nvita.utils import open_json\n",
    "from nvita.utils import to_json\n",
    "from nvita.models.data import SplittedTSData\n",
    "from nvita.models.cnn import CNN\n",
    "from nvita.models.lstm import LSTM\n",
    "from nvita.models.gru import GRU\n",
    "from nvita.models.rf import RF\n",
    "import nvita.models.train as mt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seeds': ['2210', '9999', '58361', '789789', '1111111'], 'data': ['Electricity', 'NZTemp', 'CNYExch', 'Oil'], 'y_col_name': ['Consumption', 'Auckland', 'Close', 'Close'], 'window_size': ['4', '3', '7', '7'], 'models': ['CNN', 'LSTM', 'GRU', 'RF'], 'attacks': ['FGSM', 'BIM', 'nVITA', 'fullVITA']}\n"
     ]
    }
   ],
   "source": [
    "PATH_ROOT = Path(os.getcwd()).parent.absolute()\n",
    "\n",
    "my_metadata = open_json(os.path.join(\n",
    "    PATH_ROOT, \"experiments\", \"metadata.json\"))\n",
    "print(my_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = my_metadata[\"seeds\"]\n",
    "DATA_NAMES =  my_metadata[\"data\"]\n",
    "Y_COL_NAMES = my_metadata[\"y_col_name\"]\n",
    "WINDOW_SIZES = my_metadata[\"window_size\"]\n",
    "MODELS = my_metadata[\"models\"]\n",
    "TEST_SIZE = 100\n",
    "VALID_PER = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split All Dataset for All Seeds and Save them on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Electricity_seed_2210.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Electricity_seed_9999.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Electricity_seed_58361.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Electricity_seed_789789.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Electricity_seed_1111111.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_NZTemp_seed_2210.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_NZTemp_seed_9999.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_NZTemp_seed_58361.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_NZTemp_seed_789789.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_NZTemp_seed_1111111.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_CNYExch_seed_2210.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_CNYExch_seed_9999.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_CNYExch_seed_58361.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_CNYExch_seed_789789.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_CNYExch_seed_1111111.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Oil_seed_2210.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Oil_seed_9999.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Oil_seed_58361.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Oil_seed_789789.pkl has already existed!\n",
      "File c:\\Users\\markc\\Working_Space\\nvita\\results\\splitted_data\\df_Oil_seed_1111111.pkl has already existed!\n"
     ]
    }
   ],
   "source": [
    "for data_ind in range(len(DATA_NAMES)):\n",
    "    for seed in SEEDS:\n",
    "        path_df = os.path.join(PATH_ROOT, \"data\", \"clean_data\", DATA_NAMES[data_ind] +\".csv\")\n",
    "\n",
    "        s_data = SplittedTSData(path_df, DATA_NAMES[data_ind], Y_COL_NAMES[data_ind], int(WINDOW_SIZES[data_ind]), int(seed))\n",
    "        s_data.train_valid_test_split(TEST_SIZE, VALID_PER)\n",
    "        s_data.save_splitted_data(PATH_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_cnn(s_d):\n",
    "    max_epochs = [100, 250, 500]\n",
    "    learning_rate = [0.001, 0.005, 0.01]\n",
    "    window_size = s_data.window_size\n",
    "    #module__window_size = window_size\n",
    "    module__conv_out_and_f1 = [64, 128, 256]\n",
    "    f0 = s_d.X_train.shape[2]\n",
    "    #module__f1 = [64, 128, 256, 512]\n",
    "    module__f2 = [32, 64 ,128]\n",
    "    out = s_d.y_train.shape[1]\n",
    "\n",
    "    best_score = np.Inf\n",
    "    best_cnn_paras = []\n",
    "    for epoch in max_epochs:\n",
    "        for lr in learning_rate: \n",
    "            for c in module__conv_out_and_f1:\n",
    "                f1 = c\n",
    "                for f2 in module__f2:\n",
    "                    model = CNN(window_size, c, f0, f1, f2, out)\n",
    "                    mt.train(model, lr, epoch, s_d.X_train, s_d.y_train)\n",
    "                    score = np.mean(mt.evaluate(model, s_d.X_valid, s_d.y_valid)**2)\n",
    "                    if score < best_score:\n",
    "                        # Smaller score MSE indicates better performance\n",
    "                        best_score = score\n",
    "                        best_cnn_paras = [epoch, lr, window_size, c, f0, f1, f2, out]\n",
    "    print(\"Best Score for \" + model_name + \" is \" + str(best_score) + \" on dataset \" + str(s_d.df_name))\n",
    "    return best_cnn_paras\n",
    "\n",
    "def grid_search_rnn(s_d, model_name = \"LSTM\"):\n",
    "    max_epochs = [100, 250, 500]\n",
    "    learning_rate = [0.001, 0.005, 0.01]\n",
    "    #module__window_size = window_size\n",
    "    input_dim = s_d.X_train.shape[2]\n",
    "    module__hidden_dim = [64, 128, 256]\n",
    "    module__num_layers = [1, 2, 4]\n",
    "    output_dim = s_d.y_train.shape[1]\n",
    "\n",
    "    best_score = np.Inf\n",
    "    best_rnn_paras = []\n",
    "    for epoch in max_epochs:\n",
    "        for lr in learning_rate: \n",
    "            for hidden_dim in module__hidden_dim:\n",
    "                for num_layers in module__num_layers:\n",
    "                    if model_name == \"LSTM\":\n",
    "                        model = LSTM(input_dim, hidden_dim, num_layers, output_dim)\n",
    "                    elif model_name == \"GRU\":\n",
    "                        model = GRU(input_dim, hidden_dim, num_layers, output_dim)\n",
    "                    mt.train(model, lr, epoch, s_d.X_train, s_d.y_train)\n",
    "                    score = np.mean(mt.evaluate(model, s_d.X_valid, s_d.y_valid)**2)\n",
    "                    if score < best_score:\n",
    "                        # Smaller score MSE indicates better performance\n",
    "                        best_score = score\n",
    "                        best_rnn_paras = [epoch, lr, input_dim, hidden_dim, num_layers, output_dim]\n",
    "    print(\"Best Score for \" + model_name + \" is \" + str(best_score) + \" on dataset \" + str(s_d.df_name))\n",
    "    return best_rnn_paras\n",
    "\n",
    "def grid_search_rf(s_d):\n",
    "    module__n_estimators = [100, 250, 500, 1000]\n",
    "\n",
    "    best_score = np.Inf\n",
    "    best_rf_paras = []\n",
    "    for n_estimators in module__n_estimators:\n",
    "        model = RF(n_estimators)\n",
    "        model.fit(s_d.X_train, s_d.y_train)\n",
    "        score = np.mean(mt.evaluate(model, s_d.X_valid, s_d.y_valid)**2)\n",
    "        if score < best_score:\n",
    "            # Smaller score MSE indicates better performance\n",
    "            best_score = score\n",
    "            best_rf_paras = [n_estimators]\n",
    "    print(\"Best Score for \" + model_name + \" is \" + str(best_score) + \" on dataset \" + str(s_d.df_name))\n",
    "    return best_rf_paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for CNN is 0.008788654 on dataset Electricity\n",
      "Best Score for LSTM is 0.0103443805 on dataset Electricity\n",
      "Best Score for GRU is 0.010461737 on dataset Electricity\n",
      "Best Score for RF is 0.008242441980566248 on dataset Electricity\n",
      "Best Score for CNN is 0.00413001 on dataset NZTemp\n",
      "Best Score for LSTM is 0.003927458 on dataset NZTemp\n",
      "Best Score for GRU is 0.0039587216 on dataset NZTemp\n",
      "Best Score for RF is 0.004263880358766855 on dataset NZTemp\n",
      "Best Score for CNN is 0.0005453153 on dataset CNYExch\n",
      "Best Score for LSTM is 0.0005381186 on dataset CNYExch\n",
      "Best Score for GRU is 0.00050806394 on dataset CNYExch\n",
      "Best Score for RF is 0.0004264621730835292 on dataset CNYExch\n",
      "Best Score for CNN is 0.00018547614 on dataset Oil\n",
      "Best Score for LSTM is 0.00019189763 on dataset Oil\n",
      "Best Score for GRU is 0.00017004524 on dataset Oil\n",
      "Best Score for RF is 0.00019938440854457787 on dataset Oil\n"
     ]
    }
   ],
   "source": [
    "best_cnn_paras_dict = dict()\n",
    "bset_lstm_paras_dict = dict()\n",
    "best_gru_paras_dict = dict()\n",
    "best_rf_paras_dict = dict()\n",
    "for data_ind in range(len(DATA_NAMES)):\n",
    "    seed = SEEDS[0]\n",
    "    s_data = SplittedTSData()\n",
    "    s_data = s_data.load_splitted_data(PATH_ROOT, DATA_NAMES[data_ind], seed)\n",
    "    for model_name in MODELS:\n",
    "        if model_name == \"CNN\":\n",
    "            best_cnn_paras_dict[DATA_NAMES[data_ind]] = grid_search_cnn(s_data)\n",
    "        elif model_name == \"LSTM\":\n",
    "            bset_lstm_paras_dict[DATA_NAMES[data_ind]] = grid_search_rnn(s_data, model_name)\n",
    "        elif model_name == \"GRU\":\n",
    "            best_gru_paras_dict[DATA_NAMES[data_ind]] = grid_search_rnn(s_data, model_name)\n",
    "        elif model_name == \"RF\":\n",
    "            best_rf_paras_dict[DATA_NAMES[data_ind]] = grid_search_rf(s_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paras_dict = dict()\n",
    "\n",
    "all_paras_dict[\"CNN\"] = best_cnn_paras_dict \n",
    "all_paras_dict[\"LSTM\"] = bset_lstm_paras_dict \n",
    "all_paras_dict[\"GRU\"] = best_gru_paras_dict \n",
    "all_paras_dict[\"RF\"] = best_rf_paras_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_json(all_paras_dict , os.path.join(\n",
    "    PATH_ROOT, \"experiments\", \"model_paras.json\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('hons')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c602aa022b826db5d2ce365c7625b4d6ed5ee23662e175f9578855d0b85dec78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
