{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from nvita.utils import open_json\n",
    "from nvita.utils import to_json\n",
    "from nvita.models.data import SplittedTSData\n",
    "from nvita.models.cnn import CNN\n",
    "from nvita.models.lstm import LSTM\n",
    "from nvita.models.gru import GRU\n",
    "from nvita.models.rf import RF\n",
    "from nvita.models.utils import save_model, load_model\n",
    "import nvita.models.train as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\na_dict = dict()\\na_dict[\"Electricity\"] = {\"CNN\" : [500, 0.001, 4, 64, 3, 64, 64, 1], \"LSTM\" : [500, 0.001, 3, 64, 1, 1], \"GRU\": [500, 0.001, 3, 64, 1, 1], \"RF\":[500]}\\n\\nto_json(a_dict, os.path.join(\\n    PATH_ROOT, \"experiments\", \"model_paras.json\"))\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "a_dict = dict()\n",
    "a_dict[\"Electricity\"] = {\"CNN\" : [500, 0.001, 4, 64, 3, 64, 64, 1], \"LSTM\" : [500, 0.001, 3, 64, 1, 1], \"GRU\": [500, 0.001, 3, 64, 1, 1], \"RF\":[500]}\n",
    "\n",
    "to_json(a_dict, os.path.join(\n",
    "    PATH_ROOT, \"experiments\", \"model_paras.json\"))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Electricity': {'CNN': [500, 0.001, 4, 64, 3, 64, 64, 1], 'LSTM': [500, 0.001, 3, 64, 1, 1], 'GRU': [500, 0.001, 3, 64, 1, 1], 'RF': [500]}}\n"
     ]
    }
   ],
   "source": [
    "PATH_ROOT = Path(os.getcwd()).parent.absolute()\n",
    "\n",
    "my_metadata = open_json(os.path.join(\n",
    "    PATH_ROOT, \"experiments\", \"metadata.json\"))\n",
    "\n",
    "model_paras = open_json(os.path.join(\n",
    "    PATH_ROOT, \"experiments\", \"model_paras.json\"))\n",
    "print(model_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = my_metadata[\"seeds\"]\n",
    "MODELS = my_metadata[\"models\"]\n",
    "DATA_NAMES =  my_metadata[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models_based_on_model_paras(model_paras_dict, s_d):\n",
    "    for model_name in MODELS:\n",
    "        if model_name != \"RF\":\n",
    "            if model_name == \"CNN\":\n",
    "                epoch, lr, window_size, c, f0, f1, f2, out = model_paras_dict[s_d.df_name][model_name]\n",
    "                model = CNN(window_size, c, f0, f1, f2, out)\n",
    "            elif model_name == \"LSTM\":\n",
    "                epoch, lr, input_dim, hidden_dim, num_layers, output_dim = model_paras_dict[s_d.df_name][model_name]\n",
    "                model = LSTM(input_dim, hidden_dim, num_layers, output_dim)\n",
    "            elif model_name == \"GRU\":\n",
    "                epoch, lr, input_dim, hidden_dim, num_layers, output_dim = model_paras_dict[s_d.df_name][model_name]\n",
    "                model = GRU(input_dim, hidden_dim, num_layers, output_dim)\n",
    "            mt.train(model, lr, epoch, s_d.X_train, s_d.y_train)\n",
    "        else:\n",
    "            # model_name == \"RF\"\n",
    "            n_estimators = model_paras_dict[s_d.df_name][model_name][0]\n",
    "            model = RF(n_estimators)\n",
    "            model.fit(s_d.X_train, s_d.y_train)\n",
    "        score = np.mean(mt.evaluate(model, s_d.X_test, s_d.y_test)**2)\n",
    "        save_model(model, PATH_ROOT, s_d.df_name, s_d.seed)\n",
    "        print(\"Best Score for \" + model_name + \" is \" + str(score) + \" on dataset \" + str(s_d.df_name) + \" with seed \" + str(s_d.seed))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for CNN is 0.030555123 on dataset Electricity with seed 2210\n",
      "Best Score for LSTM is 0.029053124 on dataset Electricity with seed 2210\n",
      "Best Score for GRU is 0.030408725 on dataset Electricity with seed 2210\n",
      "Best Score for RF is 0.010595608996610556 on dataset Electricity with seed 2210\n",
      "Best Score for CNN is 0.03050473 on dataset Electricity with seed 9999\n",
      "Best Score for LSTM is 0.025970764 on dataset Electricity with seed 9999\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\markc\\Working_Space\\nvita\\experiments\\step3_train_model.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/markc/Working_Space/nvita/experiments/step3_train_model.ipynb#ch0000012?line=3'>4</a>\u001b[0m s_data \u001b[39m=\u001b[39m SplittedTSData()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/markc/Working_Space/nvita/experiments/step3_train_model.ipynb#ch0000012?line=4'>5</a>\u001b[0m s_data \u001b[39m=\u001b[39m s_data\u001b[39m.\u001b[39mload_splitted_data(PATH_ROOT, DATA_NAMES[data_ind], seed)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/markc/Working_Space/nvita/experiments/step3_train_model.ipynb#ch0000012?line=5'>6</a>\u001b[0m train_models_based_on_model_paras(model_paras, s_data)\n",
      "\u001b[1;32mc:\\Users\\markc\\Working_Space\\nvita\\experiments\\step3_train_model.ipynb Cell 6'\u001b[0m in \u001b[0;36mtrain_models_based_on_model_paras\u001b[1;34m(model_paras_dict, s_d)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markc/Working_Space/nvita/experiments/step3_train_model.ipynb#ch0000009?line=10'>11</a>\u001b[0m         epoch, lr, input_dim, hidden_dim, num_layers, output_dim \u001b[39m=\u001b[39m model_paras_dict[s_d\u001b[39m.\u001b[39mdf_name][model_name]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markc/Working_Space/nvita/experiments/step3_train_model.ipynb#ch0000009?line=11'>12</a>\u001b[0m         model \u001b[39m=\u001b[39m GRU(input_dim, hidden_dim, num_layers, output_dim)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/markc/Working_Space/nvita/experiments/step3_train_model.ipynb#ch0000009?line=12'>13</a>\u001b[0m     mt\u001b[39m.\u001b[39;49mtrain(model, lr, epoch, s_d\u001b[39m.\u001b[39;49mX_train, s_d\u001b[39m.\u001b[39;49my_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markc/Working_Space/nvita/experiments/step3_train_model.ipynb#ch0000009?line=13'>14</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markc/Working_Space/nvita/experiments/step3_train_model.ipynb#ch0000009?line=14'>15</a>\u001b[0m     \u001b[39m# model_name == \"RF\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/markc/Working_Space/nvita/experiments/step3_train_model.ipynb#ch0000009?line=15'>16</a>\u001b[0m     n_estimators \u001b[39m=\u001b[39m model_paras_dict[s_d\u001b[39m.\u001b[39mdf_name][model_name][\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32md:\\Programming\\IDE\\Anaconda\\envs\\hons\\lib\\site-packages\\nvita\\models\\train.py:19\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, lr, num_epochs, x_train, y_train, print_time)\u001b[0m\n\u001b[0;32m     17\u001b[0m     losses[epoch] \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     18\u001b[0m     optimiser\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 19\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     20\u001b[0m     optimiser\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     21\u001b[0m cost_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32md:\\Programming\\IDE\\Anaconda\\envs\\hons\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32md:\\Programming\\IDE\\Anaconda\\envs\\hons\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#for data_ind in range(len(DATA_NAMES)):\n",
    "for data_ind in range(1):\n",
    "    for seed in SEEDS:\n",
    "        s_data = SplittedTSData()\n",
    "        s_data = s_data.load_splitted_data(PATH_ROOT, DATA_NAMES[data_ind], seed)\n",
    "        train_models_based_on_model_paras(model_paras, s_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s_data = SplittedTSData()\n",
    "s_data = s_data.load_splitted_data(PATH_ROOT, DATA_NAMES[0], SEEDS[0])\n",
    "m = load_model(PATH_ROOT, s_data.df_name, SEEDS[0], \"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\markc\\Working_Space\\nvita\\experiments\\step3_train_model.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/markc/Working_Space/nvita/experiments/step3_train_model.ipynb#ch0000014?line=0'>1</a>\u001b[0m y_p \u001b[39m=\u001b[39m mt\u001b[39m.\u001b[39;49mpredict(m, s_data\u001b[39m.\u001b[39;49mX_test)\n",
      "File \u001b[1;32md:\\Programming\\IDE\\Anaconda\\envs\\hons\\lib\\site-packages\\nvita\\models\\train.py:40\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(model, X)\u001b[0m\n\u001b[0;32m     38\u001b[0m     result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mrf_pytorch_predict(X)\n\u001b[0;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 40\u001b[0m     model\u001b[39m.\u001b[39;49meval()\n\u001b[0;32m     41\u001b[0m     result \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m     42\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "y_p = mt.predict(m, s_data.X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('hons')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c602aa022b826db5d2ce365c7625b4d6ed5ee23662e175f9578855d0b85dec78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
